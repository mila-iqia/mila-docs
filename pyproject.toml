[project]
name = "mila-docs"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
requires-python = ">=3.12"
dependencies = []

[tool.uv.workspace]
members = [
    "docs/examples/frameworks/pytorch_setup",
    "docs/examples/frameworks/jax_setup",
    "docs/examples/frameworks/jax",
    "docs/examples/distributed/single_gpu",
    "docs/examples/distributed/multi_gpu",
    "docs/examples/distributed/multi_node",
    "docs/examples/advanced/imagenet",
    "docs/examples/good_practices/checkpointing",
    # Add back when Orion is compatible with Python >=3.12
    # "docs/examples/good_practices/hpo_with_orion",
    "docs/examples/good_practices/launch_many_jobs",
    "docs/examples/good_practices/many_tasks_per_gpu",
    "docs/examples/good_practices/slurm_job_arrays",
    "docs/examples/good_practices/wandb_setup",
]

[dependency-groups]
dev = [
    "myst-parser>=0.14.0",
    "pre-commit>=4.2.0",
    "recommonmark>=0.7.1",
    "rstcheck[sphinx]>=6.2.5",
    "sphinx>=4.0.2",
    "sphinx-copybutton>=0.3.1",
    "sphinx-lint>=1.0.0",
    "sphinx-prompt>=1.4.0",
    "sphinx-readable-theme>=1.3.0",
    "sphinx-rtd-theme>=0.5.2",
    "sphinx-theme>=1.0",
    "urllib3<2",
]
test = [
    "pytest>=9.0.1",
    "pytest-regressions>=2.8.3",
    "pytest-xdist>=3.8.0",
    "setuptools>=80.9.0",
    "submitit>=1.5.3",
]

[tool.hatch.envs.default]
installer = "uv"
dependency-groups = ["dev"]
post-install-commands = [
    "uv sync",
    "uv run pre-commit install",
]

[tool.hatch.envs.default.scripts]
uv = 'UV_PROJECT_ENVIRONMENT="{env:VIRTUAL_ENV}" "$(which uv)" {args}'
build = [
    "uv run sphinx-build -b html '{root:real}/docs' '{root:real}/docs'/_build/",
]

[tool.hatch.envs.hatch-test]
installer = "uv"
dependency-groups = ["dev", "test"]
post-install-commands = [
    "uv sync --group test --inexact",
]

[tool.hatch.envs.hatch-test.extra-scripts]
uv = 'UV_PROJECT_ENVIRONMENT="{env:VIRTUAL_ENV}" "$(which uv)" {args}'

[tool.hatch.envs.docsgpt]
template = "default"
skip-install = true

[tool.hatch.envs.docsgpt.env-vars]
LLM_PROVIDER = "{env:LLM_PROVIDER:openai}"
LLM_NAME = "{env:LLM_NAME:nemotron-3-nano:30b}"
EMBEDDINGS_NAME = "{env:EMBEDDINGS_NAME:huggingface_sentence-transformers/all-mpnet-base-v2}"
API_KEY = "{env:API_KEY:}"
AUTH_TYPE = "{env:AUTH_TYPE:None}"
OLLAMA_HOST = "{env:OLLAMA_HOST:localhost:11434}"
OPENAI_BASE_URL = "{env:OPENAI_BASE_URL:http://{env:OLLAMA_HOST:localhost:11434}/v1}"
UV_NO_SYNC = "1"

[tool.hatch.envs.docsgpt.scripts]
setup = [
    "hatch run ollama:install",
    "git submodule update --init --recursive '{root:real}'/DocsGPT",
    "curl -sL https://d3dg1063dc54p9.cloudfront.net/models/embeddings/mpnet-base-v2.zip -o /tmp/mpnet-base-v2.zip",
    "unzip /tmp/mpnet-base-v2.zip -d '{root:real}'/DocsGPT/models/",
    "uv pip install -r '{root:real}'/DocsGPT/application/requirements.txt",
    "docker compose -f '{root:real}'/DocsGPT/deployment/docker-compose-dev.yaml build",
]
serve = [
    "- ollama serve &",
    "docker compose -f '{root:real}'/DocsGPT/deployment/docker-compose-dev.yaml up --detach",
    "uv run celery --workdir '{root:real}'/DocsGPT -A application.app.celery worker --loglevel INFO --pool solo -n 'docsgpt.%h.0' --detach",
    "uv run celery --workdir '{root:real}'/DocsGPT -A application.app.celery worker --loglevel INFO --pool solo -n 'docsgpt.%h.1' --detach",
    "uv run flask --app '{root:real}'/DocsGPT/application/app.py run --host=localhost --port=7091"
]
stop = [
    "uv run celery --workdir '{root:real}'/DocsGPT -A application.app.celery control shutdown || true",
    "docker compose -f '{root:real}'/DocsGPT/deployment/docker-compose-dev.yaml down",
]

[tool.hatch.envs.ollama]
detached = true

[tool.hatch.envs.ollama.scripts]
install-linux = [
    """which ollama >/dev/null \
        || curl -fsSL https://ollama.com/install.sh | sh""",
]
install-macos = [
    """which ollama >/dev/null \
        || curl -sL https://ollama.com/download/Ollama.dmg -o /tmp/Ollama.dmg""",
    """which ollama >/dev/null \
        || echo Install Ollama using the downloaded dmg file at /tmp/Ollama.dmg""",
    """which ollama >/dev/null \
        || open /tmp/Ollama.dmg""",
    """which ollama >/dev/null \
        || read Press Enter to continue once Ollama is installed""",
]

[tool.hatch.envs.ollama.overrides]
platform.linux.scripts = [
  "install=install-linux",
]
platform.macos.scripts = [
  "install=install-macos",
]

[tool.hatch.envs.npm]
detached = true

[tool.hatch.envs.npm.env-vars]
NVM_VERSION = "{env:NVM_VERSION:0.40.3}"

[tool.hatch.envs.npm.scripts]
_load_nvm = '[ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh"'
install-linux = [
    """_load_nvm \
        || curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v{env:NVM_VERSION}/install.sh | bash""",
    "_load_nvm",
    """which npm >/dev/null \
        || nvm install --lts""",
]
install-macos = [
    """_load_nvm \
        || curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v{env:NVM_VERSION}/install.sh | bash""",
    "_load_nvm",
    """which npm >/dev/null \
        || nvm install --lts""",
]

[tool.hatch.envs.npm.overrides]
platform.linux.scripts = [
  "install=install-linux",
]
platform.macos.scripts = [
  "install=install-macos",
]

[tool.hatch.envs.vite]
template = "default"
skip-install = true

[tool.hatch.envs.vite.scripts]
install = [
    "hatch run npm:install",
]
build = [
    "hatch run default:build",
    "cd '{root:real}/docs/_build' && npm install"
]
serve = [
    "cd '{root:real}/docs/_build' && npx vite {args}"
]
